{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b1c12d1",
   "metadata": {},
   "source": [
    "# DCGAN (Deep-Convolutional-GAN)\n",
    "\n",
    "Tensorflow 튜토리얼을 보고 따라 만든 모델([링크](https://www.tensorflow.org/tutorials/generative/dcgan))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f57c33",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c7b51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense \n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__) # Version Check (2.*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480d88f5",
   "metadata": {},
   "source": [
    "## Constants\n",
    "해당 모델에서 사용할 설정값 모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d726214b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will generate **96px** square images.\n"
     ]
    }
   ],
   "source": [
    "# 생성할 해상도 값 - 반드시 제곱수여야하며 훈련데이터도 그에 맞춰 스케일링 필요\n",
    "# 4 이상으로 설정 시 메모리가 부족할 수 있음 주의 (코랩에서는 부족)\n",
    "GENERATE_RES = 3 # (1=32, 2=64, 3=96, 4=128, etc.)\n",
    "GENERATE_SQUARE = 32 * GENERATE_RES # rows/cols (should be square)\n",
    "IMAGE_CHANNELS = 3 # RGB\n",
    "\n",
    "# Preview image \n",
    "PREVIEW_ROWS = 4\n",
    "PREVIEW_COLS = 7\n",
    "PREVIEW_MARGIN = 16\n",
    "\n",
    "# Size vector to generate images from\n",
    "SEED_SIZE = 100\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = 'data' # 폴더가 없으면 만들어놓자\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 60000\n",
    "\n",
    "print(f\"Will generate **{GENERATE_SQUARE}px** square images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58cbab6",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "몇가지 도우미 함수들\n",
    "- 걸린 시간을 이쁘게 출력하는 함수\n",
    "- 에포크마다 생성한 이미지를 저장하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775497b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b965d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(cnt,noise):\n",
    "    image_array = np.full(\n",
    "        (\n",
    "            PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)),\n",
    "            PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), IMAGE_CHANNELS\n",
    "        ),\n",
    "        255,\n",
    "        dtype=np.uint8\n",
    "    )\n",
    "\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "    image_count = 0\n",
    "    for row in range(PREVIEW_ROWS):\n",
    "        for col in range(PREVIEW_COLS):\n",
    "            r = row * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
    "            c = col * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
    "            image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE] \\\n",
    "                = generated_images[image_count] * 255\n",
    "            image_count += 1\n",
    "\n",
    "\n",
    "    output_path = os.path.join(DATA_PATH,'output')\n",
    "    if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "    filename = os.path.join(output_path,f\"train-{cnt}.png\")\n",
    "    im = Image.fromarray(image_array)\n",
    "    im.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628922cc",
   "metadata": {},
   "source": [
    "## Load Datasets\n",
    "- 훈련 이미지들은 `DATA_PATH/face_images` 경로에 있어야 한다\n",
    "- 설정한 해상도로 데이터셋 리사이징\n",
    "- 불러온 이미지는 numpy 바이너리로 저장하여 추후 재사용\n",
    "- 마지막으로 데이터셋을 Tensorflow Dataset 객체로 변환하여 셔플 및 배치화함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba61dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_binary_path = os.path.join(\n",
    "    DATA_PATH,\n",
    "    f'training_data_{GENERATE_SQUARE}_{GENERATE_SQUARE}.npy'\n",
    ")\n",
    "\n",
    "print(f\"Looking for file: {training_binary_path}\")\n",
    "\n",
    "if not os.path.isfile(training_binary_path):\n",
    "    start = time.time()\n",
    "    print(\"Loading training images...\")\n",
    "    training_data = []\n",
    "    faces_path = os.path.join(DATA_PATH,'face_images')\n",
    "    for filename in tqdm(os.listdir(faces_path)):\n",
    "        path = os.path.join(faces_path,filename)\n",
    "        image = Image.open(path).resize((GENERATE_SQUARE, GENERATE_SQUARE),Image.ANTIALIAS)\n",
    "        training_data.append(np.asarray(image))\n",
    "        training_data = np.reshape(training_data,(-1,GENERATE_SQUARE, GENERATE_SQUARE,IMAGE_CHANNELS))\n",
    "    training_data = training_data.astype(np.float32)\n",
    "    training_data = training_data / 127.5 - 1.\n",
    "\n",
    "\n",
    "    print(\"Saving training image binary...\")\n",
    "    np.save(training_binary_path, training_data)\n",
    "    elapsed = time.time() - start\n",
    "    print (f'Image preprocess time: {hms_string(elapsed)}')\n",
    "else:\n",
    "    print(\"Loading previous training pickle...\")\n",
    "    training_data = np.load(training_binary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(training_data) \\\n",
    "    .shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d7614d",
   "metadata": {},
   "source": [
    "## Build Model\n",
    "Generator와 Discriminator 모델을 만든다. (Sequential 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6529ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(seed_size, channels):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(4*4*256,activation=\"relu\",input_dim=seed_size))\n",
    "    model.add(Reshape((4,4,256)))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "   \n",
    "    # Output resolution, additional upsampling\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    if GENERATE_RES>1:\n",
    "        model.add(UpSampling2D(size=(GENERATE_RES,GENERATE_RES)))\n",
    "        model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "    # Final CNN layer\n",
    "    model.add(Conv2D(channels,kernel_size=3,padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, \n",
    "                     padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8ee79d",
   "metadata": {},
   "source": [
    "## Initial Results\n",
    "훈련하기 전 Generator와 Discriminator의 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97435454",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator(SEED_SIZE, IMAGE_CHANNELS)\n",
    "\n",
    "noise = tf.random.normal([1, SEED_SIZE])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb957ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (GENERATE_SQUARE,GENERATE_SQUARE,IMAGE_CHANNELS)\n",
    "\n",
    "discriminator = build_discriminator(image_shape)\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a0977a",
   "metadata": {},
   "source": [
    "## Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e9b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d2560",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "만일 다른 해상도(`GENERATE_RES`)를 쓴다면 `learning_rate`를 변경할 필요가 있음 (다른 하이퍼파라미터도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13321b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802e7ec",
   "metadata": {},
   "source": [
    "## Define Training\n",
    "`@tf.function` 데코레이터는 이 훈련함수를 precompile 시켜 성능을 높여준다. 그리고 `tf.GradientTape()`을 사용하여 Generator와 Discriminator의 학습을 각각 진행할 수 있게 했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(seed, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss,\n",
    "                                                   generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss,\n",
    "                                                        discriminator.trainable_variables)\n",
    "\n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator,\n",
    "                                                generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator,\n",
    "                                                    discriminator.trainable_variables))\n",
    "        \n",
    "    return gen_loss,disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a53fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, SEED_SIZE))\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        gen_loss_list = []\n",
    "        disc_loss_list = []\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            t = train_step(image_batch)\n",
    "            gen_loss_list.append(t[0])\n",
    "            disc_loss_list.append(t[1])\n",
    "\n",
    "        g_loss = sum(gen_loss_list) / len(gen_loss_list)\n",
    "        d_loss = sum(disc_loss_list) / len(disc_loss_list)\n",
    "\n",
    "        epoch_elapsed = time.time() - epoch_start\n",
    "        print(f'Epoch {epoch+1}, gen loss={g_loss},disc loss={d_loss}, {hms_string(epoch_elapsed)}')\n",
    "        save_images(epoch, fixed_seed)\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    print(f'Training time: {hms_string(elapsed)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eef255e",
   "metadata": {},
   "source": [
    "## 실제 트레이닝\n",
    "아래 셀을 실행하면 훈련이 시작된다 (시간이 무척 오래걸림 주의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS) # Constants에서 EPOCHS를 설정하라"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c99515",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save(os.path.join(DATA_PATH,\"face_generator.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbb472f",
   "metadata": {},
   "source": [
    "## Model Test\n",
    "Output 폴더에 가면 에포크별로 생성한 이미지가 있다. 혹은 직접 생성하고 싶다면 아래 셀을 활용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f2746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, SEED_SIZE])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
